{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read, plot, resize data\n",
    "'''\n",
    "\n",
    "def plot(img, title = \" \"):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16,8),dpi = 80)\n",
    "    ax.imshow(img) \n",
    "    fig.suptitle(title)\n",
    "    plt.show() \n",
    "    return\n",
    "\n",
    "def read_image(path, flag = 1):\n",
    "    \n",
    "    image = cv.imread(path, flag)\n",
    "    \n",
    "    if flag == 1:\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "    return image\n",
    " \n",
    "def resize(img, scale = 20):\n",
    "    \n",
    "    width = int(img.shape[1] * scale / 100)\n",
    "    height = int(img.shape[0] * scale / 100)\n",
    "    dim = (width, height)\n",
    "  \n",
    "    return cv.resize(img, dim, interpolation = cv.INTER_AREA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Utility functions for SIFT keypoints\n",
    "'''\n",
    "\n",
    "def SIFT_descriptors(image):\n",
    "    \n",
    "    sift = cv.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "\n",
    "def draw_and_display(image, keypoints):\n",
    "    \n",
    "    draw_features = np.zeros(image.shape)\n",
    "    draw_features = cv.drawKeypoints(image, keypoints, draw_features)\n",
    "    return draw_features\n",
    "\n",
    "\n",
    "def SIFT_matching(descriptorL, descriptorR, img1, kp1, img2, kp2, display = False):\n",
    "    \n",
    "    matcher = cv.BFMatcher(cv.NORM_L2, crossCheck = True)\n",
    "    #matches = matcher.knnMatch(descriptorL, descriptorR, k = 111)\n",
    "    matches = matcher.match(descriptorL, descriptorR)\n",
    "    if len(matches) < 4:\n",
    "        print(\"Not enough correspondances!\")\n",
    "        exit(0)\n",
    "    numPoints = min(max(4, int(0.1 * len(matches))), 100)   \n",
    "    matches = sorted(matches, key = lambda x:x.distance)[0:numPoints]\n",
    "    \n",
    "    ''''\n",
    "    Sorting wrt the distance object of each match.\n",
    "    The closer the matches are, the less erroneous they are likely to be \n",
    "    '''\n",
    "    \n",
    "    if display:\n",
    "        \n",
    "        print(f\"The number of matches: {len(matches)}\")\n",
    "        print(f\"\\033[35m The number of corresponding descriptors: \\033[35m {len(matches)}\")\n",
    "        fig, ax = plt.subplots(figsize = (16, 4))\n",
    "        img1 = cv.drawMatches(img1, kp1, img2, kp2, matches, None, flags = 2|4)\n",
    "        fig.suptitle(f'The {numPoints} closest correspondences', fontsize = 16)\n",
    "        ax.imshow(img1)\n",
    "    \n",
    "    pts1 = np.float32([ kp1[m.queryIdx].pt for m in matches ]).reshape(-1,2)\n",
    "    pts2 = np.float32([ kp2[m.trainIdx].pt for m in matches ]).reshape(-1,2)\n",
    "    return pts1, pts2\n",
    "   \n",
    "    \n",
    "def get_points_descriptors(imgTrain, imgQuery, display = False):\n",
    "\n",
    "    keypointsTrain, descriptorsTrain= SIFT_descriptors(imgTrain) \n",
    "    keypointsQuery, descriptorsQuery = SIFT_descriptors(imgQuery)\n",
    "    pointsTrain, pointsQuery = SIFT_matching(descriptorsTrain, descriptorsQuery, imgTrain, keypointsTrain, imgQuery, keypointsQuery, display)\n",
    "    H = get_homography_ransac(get_homo(pointsTrain), get_homo(pointsQuery))\n",
    "\n",
    "    return pointsTrain, pointsQuery, H\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Functions for Homography estimation and RANSAC\n",
    "'''\n",
    "\n",
    "def get_homo(x):\n",
    "    \n",
    "    return np.hstack((x, np.ones(x.shape[0]).reshape(-1,1)))\n",
    "\n",
    "\n",
    "def de_homo(arr):\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        arr = np.divide(arr,(arr[:,-1].reshape(-1,1)))\n",
    "    arr[np.isnan(arr)] = 1e9\n",
    "\n",
    "    return arr[:,:-1]\n",
    "\n",
    "\n",
    "def get_homography(pointsTrain, pointsQuery):\n",
    "    \n",
    "    '''\n",
    "    homography from Query to Train, H_{12}\n",
    "    Ah = 0, least squares formulation\n",
    "    '''\n",
    "    \n",
    "    A = []\n",
    "    for p in range(pointsTrain.shape[0]):\n",
    "        xTrain = pointsTrain[p][0] ; yTrain = pointsTrain[p][1]\n",
    "        xQuery = pointsQuery[p][0] ; yQuery = pointsQuery[p][1]\n",
    "        A.append([xQuery, yQuery, 1, 0, 0, 0, -xTrain * xQuery, -xTrain * yQuery, -xTrain])\n",
    "        A.append([0, 0, 0, xQuery, yQuery, 1, -yTrain * xQuery, -yTrain * yQuery, -yTrain])\n",
    "    A = np.array(A)\n",
    "    _, _, vt = np.linalg.svd(A, full_matrices = True)\n",
    "    H = vt[-1].reshape(3, 3)\n",
    "    H = H / H[2][2]\n",
    "    return H\n",
    "\n",
    "\n",
    "def get_rmse(pointsL, pointsR, H):\n",
    "    \n",
    "    projectedL = (H @ pointsR.T).T\n",
    "    d1 = (np.isclose(pointsL, projectedL, rtol = 10e-2))\n",
    "    d1 = d1[:,1] * d1[:,0]\n",
    "    d1 = np.sum(d1)\n",
    "    return np.sqrt(np.mean((projectedL - pointsL) ** 2))\n",
    "\n",
    "\n",
    "def get_homography_ransac(pointsL, pointsR, displayError = False):\n",
    "    \n",
    "    if(pointsL.shape[0] < 4):\n",
    "        print(\"Not enough correspondances!\")\n",
    "        exit(0)\n",
    "        \n",
    "    random_index = np.arange(pointsL.shape[0])\n",
    "    H = np.zeros((3,3))\n",
    "    min_error = 10e8\n",
    "    \n",
    "    for iterations in range(9999):\n",
    "        random.shuffle(random_index)\n",
    "        pL = []\n",
    "        pR = []\n",
    "        minPointCorrespondences = 4\n",
    "        \n",
    "        for i in range(minPointCorrespondences):\n",
    "            pL.append(pointsL[random_index[i]])\n",
    "            pR.append(pointsR[random_index[i]])\n",
    "            \n",
    "        pL = np.array(pL)\n",
    "        pR = np.array(pR)\n",
    "        iter_H = get_homography(pL, pR)\n",
    "        rmse = get_rmse(pointsL, pointsR, iter_H)\n",
    "        \n",
    "        if rmse < min_error:\n",
    "            min_error = rmse\n",
    "            H = iter_H\n",
    "    if displayError:    \n",
    "        print(f\"\\033[43;77m The minimum rmse error using RANSAC is: \\033[43;77m {min_error}\")\n",
    "    return H\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Functions for image stitching\n",
    "'''\n",
    "\n",
    "def get_stitched(imgTarget, imgQuery):\n",
    "\n",
    "    pointsTarget, pointsQuery,  H = get_points_descriptors(imgTarget, imgQuery)\n",
    "    H = np.linalg.inv(H)\n",
    "    x1, y1, _ = imgTarget.shape\n",
    "    x2, y2, _ = imgQuery.shape\n",
    "    \n",
    "    '''\n",
    "    Finding the corners of the image after applying the homography\n",
    "    To find the right dimensions for warpPerspective\n",
    "    '''\n",
    "    \n",
    "     \n",
    "    getCorners = np.asarray([[0, 0], [0, x1 - 1], [y1 - 1, 0], [y1 - 1, x1 - 1]])\n",
    "    getCorners = np.int32(de_homo((H @ get_homo(getCorners).T).T))\n",
    "    getCorners = np.vstack((getCorners,[0, 0], [0, x2 - 1], [y2 - 1, x2 - 1], [y2 - 1, 0]))\n",
    "    \n",
    "    maxDim = np.max(getCorners, axis = 0)\n",
    "    minDim = np.min(getCorners, axis = 0)\n",
    "    \n",
    "    \n",
    "    if np.any(minDim < 0):\n",
    "        # If zero padding needs to be done\n",
    "        imgQueryPadded = np.pad(imgQuery, ((-minDim[1], 0), (-minDim[0] ,0), (0 ,0)), 'constant', constant_values = 0)\n",
    "        pointsTarget, pointsQuery, H = get_points_descriptors(imgTarget, imgQueryPadded)\n",
    "        H = np.linalg.inv(H)\n",
    "        \n",
    "    \n",
    "    warpedImage = cv.warpPerspective(imgTarget, H, (maxDim[0] - minDim[0] + 1, maxDim[1] - minDim[1] + 1 ), borderMode = cv.BORDER_CONSTANT, borderValue=(0, 255, 0))\n",
    "    \n",
    "    plot(warpedImage, title = \"warped Image\")\n",
    "    \n",
    "    minThreshold = np.array([0, 254, 0])    \n",
    "    maxThreshold = np.array([1, 255, 1])\n",
    "            \n",
    "    mask = cv.inRange(imgQuery, minThreshold, maxThreshold)\n",
    "    #Returns 255 if within the threshold\n",
    "    maskedImage = np.copy(imgQuery)\n",
    "    maskedImage[mask != 0] = [0, 0, 0]\n",
    "    stitchedImage = np.where( maskedImage == [0,0,0] , warpedImage[-minDim[1]:-minDim[1] + x2 ,-minDim[0]:-minDim[0] + y2, :], imgQuery)\n",
    "    warpedImage[-minDim[1]:(-minDim[1] + x2), -minDim[0]:(-minDim[0] + y2)] = stitchedImage\n",
    "    warpedImage = trim(warpedImage)\n",
    "    \n",
    "    return warpedImage\n",
    "\n",
    "def stitch_multiple(img_arr):\n",
    "    \n",
    "    #stitching multiple images irrespective of the given order\n",
    "    arr = list(range(len(img_arr)))\n",
    "    i = 0\n",
    "    while i<len(arr):\n",
    "        if i == 0:\n",
    "            out = img_arr[0] \n",
    "            i = i+1\n",
    "            continue\n",
    "        \n",
    "        out1 = get_stitched(img_arr[i],out)\n",
    "        \n",
    "        if np.all(out1==0):\n",
    "            k = arr[i]\n",
    "            arr.remove(arr[i])\n",
    "            arr.append(k)\n",
    "            \n",
    "        else:\n",
    "            out = out1\n",
    "            i=i+1\n",
    "    \n",
    "    return out\n",
    "\n",
    "def trim(frame):\n",
    "    #crop top\n",
    "    if np.all(frame[0] == np.array([0,255,0])):\n",
    "        return trim(frame[1:])\n",
    "    #crop bottom\n",
    "    elif np.all(frame[-1] == np.array([0,255,0])):\n",
    "        return trim(frame[:-2])\n",
    "    #crop left\n",
    "    elif np.all(frame[:,0] == np.array([0,255,0])):\n",
    "        return trim(frame[:,1:]) \n",
    "    #crop right\n",
    "    elif np.all(frame[:,-1] == np.array([0,255,0])):\n",
    "        return trim(frame[:,:-2])    \n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
